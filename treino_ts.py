# -*- coding: utf-8 -*-
"""treino_ts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/137LOyQ-L2D6nKqJsj7rEm0Ws3T2xIvg-

Abra o anaconda prompt e digite o seguinte para rodar de forma local:

```
jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0

```

Copie a url e cole na janela do Conectar -> Conectar ao ambiente de execução local
Isso é feito aqui no colab

# Instalação de pacotes e imports
"""

!pip install pyriemann
!pip install pylsl

from pylsl import StreamInlet, resolve_stream, StreamInfo, StreamOutlet, local_clock
import pylsl
import pickle

import random
import time
from scipy.signal                  import butter, lfilter
from scipy                         import signal

import numpy  as np
import pandas as pd

from matplotlib                    import pyplot as plt
from sklearn.metrics               import cohen_kappa_score
from sklearn.model_selection       import ShuffleSplit, cross_val_score, KFold
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model          import LogisticRegression
from pyriemann.estimation          import Covariances, XdawnCovariances
from pyriemann.tangentspace        import TangentSpace, tangent_space
from pyriemann.utils.viz           import plot_embedding
from pyriemann.utils.mean          import mean_covariance

from tensorflow.keras              import utils as np_utils

"""# Treinando Tangent Space

## Preparação das janelas de treino
"""

#################### TROQUE O NOME DO ARQUIVO AQUI ###########################
filename = ['train_bmi_seidi.csv']

# Define parâmetros
overlap_step = 0.1  # tamanho do passo para sobreposição de janelas
max_trial_t  = 3.75 # tamanho máximo de uma janela de tentativa
b, a         = butter(4, (1,40), 'bandpass', fs=512)

# Lê o arquivo csv
df_me         = pd.read_csv(filename)

# Obtém os índices dos eventos de imagética motora da mão esquerda e direita
event_id      = pd.to_numeric(df_me['Event Id'], errors='coerce').fillna(0).astype(np.int64)
left_inds     = event_id.index[event_id == 769].tolist()
right_inds    = event_id.index[event_id == 770].tolist()
  
# Frequência de amostragem
Fs            = 1/np.mean(np.diff(df_me['Time:512Hz']))

# coleta dado EEG e filtra o sinal
data_eeg      = df_me.iloc[:, 2:18].values
data_eeg      = signal.filtfilt(b, a, data_eeg.T).T
    
# Define os índices das janelas
trange        = np.arange(int(Fs*0.5),int(Fs*2.5), 4) # O 4 é pra realizar um downsample por 4
  
# Loop pelas janelas
while trange[-1] < int(max_trial_t*Fs):        

  # Obtém as janelas de imagética motora da mão esquerda
  ts            = [i + trange for i in left_inds]
  epochs_left   = data_eeg[ts,:]
  labels        = [0 for i in left_inds]
  trial_num     = [i for i in range(len(left_inds))]

  # Obtém as janelas de imagética motora da mão direita
  ts            = [i + trange for i in right_inds]
  epochs_right  = data_eeg[ts,:]
  epochs_mne    = np.vstack([epochs_left, epochs_right])
  labels        = np.append(labels, [1 for i in right_inds])
  trial_num     = np.append(trial_num, [i for i in range(len(right_inds))])

  # Concatena as janelas de ambos os lados
  data          = np.vstack([data, epochs_mne])
  all_labels    = np.append(all_labels, labels)
  all_trial_num = np.append(all_trial_num, trial_num)

  # Atualiza o índice das janelas
  trange += int(overlap_step*Fs)

# Aleatoriza as amostras
p             = np.random.permutation(len(all_labels))
data          = np.swapaxes(data[p,:,:,],1,2)
all_labels    = all_labels[p]
all_trial_num = all_trial_num[p]

"""## Validação cruzada

Essa célula valida o modelo. Se a acurácia média final for maior que 75%, podemos considerar o classificador, senão, refaça a aquisição de treino
"""

# Inicializar variáveis
best_accuracy = 0
best_kappa    = 0
best_c_mean   = None

# Definir número de folds para validação cruzada
n_folds       = 20

# Criar lista com os 20 rótulos únicos de trial
unique_labels = np.unique(all_trial_num)

# Inicializar array para armazenar resultados da validação cruzada
accuracies    = np.zeros(n_folds)
kappas        = np.zeros(n_folds)

# Fazer a validação cruzada
for fold in range(n_folds):

    # Escolher aleatoriamente 2 rótulos para o conjunto de validação
    val_labels = random.sample(list(unique_labels), 2)

    # Selecionar os índices dos dados de treinamento e validação
    train_inds           = np.where(np.logical_not(np.isin(all_trial_num, val_labels)))[0]
    val_inds             = np.where(np.isin(all_trial_num, val_labels))[0]

    # Transformar os dados em matrizes de covariância
    cov_data_train       = Covariances().transform(data[train_inds])
    cov_data_val         = Covariances().transform(data[val_inds])
    
    # Dividir os dados em conjunto de treinamento, validação e teste
    X_train, y_train     = cov_data_train, all_labels[train_inds]
    X_val, y_val         = cov_data_val, all_labels[val_inds]
    
    # Calcular a média das matrizes de covariância do conjunto de treinamento
    C_mean               = mean_covariance(X_train)
    
    # Projetar as matrizes de covariância no plano tangencial
    tan_space_covs_train = tangent_space(X_train, C_mean)
    tan_space_covs_val   = tangent_space(X_val, C_mean)
    
    # Treinar o modelo de LDA no conjunto de treinamento
    lda = LinearDiscriminantAnalysis()
    lda = LogisticRegression(random_state=0)

    lda.fit(tan_space_covs_train, y_train)
    
    # Avaliar a precisão do modelo no conjunto de validação
    accuracy = lda.score(tan_space_covs_val, y_val)
    print("\nFold", fold+1, "- Acurácia do modelo no conjunto de validação:", accuracy)
    
    y_pred_val = lda.predict(tan_space_covs_val)
    kappa_val  = cohen_kappa_score(y_val, y_pred_val)
    print("Fold", fold+1, "- Kappa do modelo no conjunto de validação:", kappa_val)
    
    # Armazenar a precisão do modelo no conjunto de validação
    accuracies[fold] = accuracy
    kappas[fold]     = kappa_val

    # Se a precisão do modelo atual for melhor que a anterior, salvar a matriz de projeção
    if kappa_val > best_kappa:
        best_kappa = kappa_val
        best_c_mean   = C_mean

# Calcular a precisão média do modelo na validação cruzada
mean_accuracy = np.mean(accuracies)
print("\nPrecisão média do modelo na validação cruzada:", mean_accuracy)

# Saving the objects:
with open('Desktop/best_c_mean.pkl', 'wb') as f: 
    pickle.dump(best_c_mean, f)

# Transformar os dados em matrizes de covariância
cov_data_train       = Covariances().transform(data)

# Calcular a média das matrizes de covariância do conjunto de treinamento
C_mean               = mean_covariance(cov_data_train)

# Projetar as matrizes de covariância no plano tangencial
tan_space_covs_train = tangent_space(cov_data_train, C_mean)

# Treinar o modelo de LDA no conjunto de treinamento
lda = LinearDiscriminantAnalysis()
lda.fit(tan_space_covs_train, all_labels)

clf = LogisticRegression().fit(tan_space_covs_train, all_labels)

# Save to file in the current working directory
pkl_filename = "Desktop/lda.pkl"
with open(pkl_filename, 'wb') as file:
    pickle.dump(clf, file)

plt.figure(figsize=(16,12))
plt.subplot(1,3,1)
plt.imshow(np.mean(np.squeeze(cov_data_train[np.where(all_labels == 1),:,:]), axis = 0))
plt.colorbar(shrink=0.5, aspect=10)
plt.title('Matriz média de covariância, mão direita')

plt.subplot(1,3,2)
plt.imshow(np.mean(np.squeeze(cov_data_train[np.where(all_labels == 0),:,:]), axis = 0))
plt.colorbar(shrink=0.5, aspect=10)
plt.title('Matriz média de covariância, mão esquerda')

plt.subplot(1,3,3)
a = np.mean(np.squeeze(cov_data_train[np.where(all_labels == 0),:,:]), axis = 0) - np.mean(np.squeeze(cov_data_train[np.where(all_labels == 1),:,:]), axis = 0)
plt.imshow(a, vmin = 0, vmax =30)
plt.colorbar(shrink=0.5, aspect=10)
plt.title('Matriz média de covariância, diferença')

_ = plot_embedding(cov_data_train, all_labels)

"""<img src="https://www.icolorpalette.com/download/solidcolorimage/383838_solid_color_background_icolorpalette.png"  class="bg-primary" width="100%">"""